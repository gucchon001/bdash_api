"""
bâ†’dash APIã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«è»¢è¨˜ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""

import requests
import pandas as pd
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional
from src.utils.environment import EnvironmentUtils as env
from src.modules.csv_to_sheet import upload_csv_to_sheet
from src.modules.spreadsheet import SpreadSheet

class BDashAPISync:
    """bâ†’dash APIã¨ã®é€£æºã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.base_url = "https://api.smart-bdash.com/api/v1"
        self.api_key = None
        self.datafile_id = None
        
    def setup_api_credentials(self) -> bool:
        """
        ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã¨ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«IDã‚’è¨­å®š
        
        Returns:
            bool: è¨­å®šæˆåŠŸæ™‚ã¯Trueã€å¤±æ•—æ™‚ã¯False
        """
        try:
            # ç’°å¢ƒå¤‰æ•°ã‚’ãƒ­ãƒ¼ãƒ‰
            env.load_env()
            
            # APIã‚­ãƒ¼ã‚’å–å¾—
            self.api_key = env.get_env_var("BDASH_API_KEY")
            if not self.api_key:
                print("âŒ bâ†’dash APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return False
                
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«IDã‚’å–å¾—
            self.datafile_id = env.get_config_value("BDASH", "datafile_id", "503")
            
            print(f"âœ… APIè¨­å®šå®Œäº†: ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ID={self.datafile_id}")
            return True
            
        except Exception as e:
            print(f"âŒ APIè¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def fetch_data(self, limit: int = 5000) -> Optional[Dict[str, Any]]:
        """
        bâ†’dash APIã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        
        Args:
            limit (int): å–å¾—ã™ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã®ä¸Šé™
            
        Returns:
            Optional[Dict[str, Any]]: å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ã€ã‚¨ãƒ©ãƒ¼æ™‚ã¯None
        """
        try:
            # ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆURL
            endpoint = f"{self.base_url}/datafiles/{self.datafile_id}/records"
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼è¨­å®š
            headers = {
                'Authorization': f'Bearer {self.api_key}',
                'Content-Type': 'application/json; charset=UTF-8'
            }
            
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
            params = {'limit': limit}
            
            print(f"ğŸš€ bâ†’dash APIã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
            print(f"ğŸ“¡ ãƒªã‚¯ã‚¨ã‚¹ãƒˆURL: {endpoint}")
            print(f"ğŸ“Š å–å¾—äºˆå®šä»¶æ•°: {limit}ä»¶")
            
            # APIãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            response = requests.get(endpoint, headers=headers, params=params)
            
            if response.status_code == 206:  # Partial Content
                data = response.json()
                print(f"âœ… ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ: {len(data.get('result', {}).get('records', []))}ä»¶")
                return data
            else:
                print(f"âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—: {response.status_code}")
                print(f"ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {response.text}")
                return None
                
        except Exception as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def convert_to_dataframe(self, data: Dict[str, Any]) -> Optional[pd.DataFrame]:
        """
        APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’Pandasã®DataFrameã«å¤‰æ›
        
        Args:
            data (Dict[str, Any]): APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            Optional[pd.DataFrame]: å¤‰æ›å¾Œã®DataFrameã€ã‚¨ãƒ©ãƒ¼æ™‚ã¯None
        """
        try:
            if 'result' not in data:
                print("âŒ ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ãŒä¸æ­£ã§ã™")
                return None
            
            result = data['result']
            header_info = result.get('header_info', [])
            records = result.get('records', [])
            
            if not header_info or not records:
                print("âŒ ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±ã¾ãŸã¯ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return None
            
            # DataFrameã‚’ä½œæˆ
            df = pd.DataFrame(records)
            
            # ã‚«ãƒ©ãƒ åã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆï¼ˆå†…éƒ¨ID â†’ æ—¥æœ¬èªåï¼‰
            column_mapping = {}
            for col in header_info:
                # å†…éƒ¨çš„ãªã‚«ãƒ©ãƒ IDã‚’å°æ–‡å­—ã«å¤‰æ›
                internal_id = col.get('column_id', '').lower()
                # å®Ÿéš›ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã§ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹å½¢å¼ã«åˆã‚ã›ã‚‹
                for record in records:
                    for key in record.keys():
                        if key.lower() == internal_id:
                            column_mapping[key] = col.get('column_name', key)
                            break
            
            # ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªåã«å¤‰æ›
            original_columns = df.columns.tolist()
            new_columns = []
            for col in original_columns:
                japanese_name = column_mapping.get(col, col)
                new_columns.append(japanese_name)
            
            df.columns = new_columns
            
            # é…ä¿¡å¹´æœˆã§ä¸¦ã¹æ›¿ãˆï¼ˆæ˜‡é †ï¼‰
            date_column = None
            for col in df.columns:
                if 'é…ä¿¡å¹´æœˆ' in col or 'å¹´æœˆ' in col:
                    date_column = col
                    break
            
            if date_column:
                print(f"ğŸ“… é…ä¿¡å¹´æœˆã‚«ãƒ©ãƒ  '{date_column}' ã§æ˜‡é †ã«ä¸¦ã¹æ›¿ãˆã¾ã™")
                try:
                    # YYYY/MMå½¢å¼ã‚’YYYY-MM-01å½¢å¼ã«å¤‰æ›ã—ã¦ã‚½ãƒ¼ãƒˆ
                    df['_sort_date'] = pd.to_datetime(df[date_column] + '/01', format='%Y/%m/%d', errors='coerce')
                    df_sorted = df.sort_values('_sort_date', ascending=True)
                    df_sorted = df_sorted.drop('_sort_date', axis=1)  # ã‚½ãƒ¼ãƒˆç”¨ã‚«ãƒ©ãƒ ã‚’å‰Šé™¤
                    df = df_sorted
                    print(f"âœ… é…ä¿¡å¹´æœˆã§æ˜‡é †ã«ä¸¦ã¹æ›¿ãˆã¾ã—ãŸ")
                except Exception as e:
                    print(f"âš ï¸ é…ä¿¡å¹´æœˆã®ä¸¦ã¹æ›¿ãˆã«å¤±æ•—: {e}")
                    print("ğŸ“‹ å…ƒã®é †åºã§ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã¾ã™")
            
            print(f"ğŸ“Š DataFrameä½œæˆå®Œäº†: {len(df)}è¡Œ Ã— {len(df.columns)}åˆ—")
            return df
            
        except Exception as e:
            print(f"âŒ DataFrameå¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def save_to_csv(self, df: pd.DataFrame, filename: Optional[str] = None) -> Optional[str]:
        """
        DataFrameã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        
        Args:
            df (pd.DataFrame): ä¿å­˜ã™ã‚‹DataFrame
            filename (Optional[str]): ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆNoneã®å ´åˆã¯è‡ªå‹•ç”Ÿæˆï¼‰
            
        Returns:
            Optional[str]: ä¿å­˜ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã€ã‚¨ãƒ©ãƒ¼æ™‚ã¯None
        """
        try:
            # dataãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
            os.makedirs('data', exist_ok=True)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
            if filename is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"bdash_datafile_{self.datafile_id}_{timestamp}.csv"
            
            filepath = f'data/{filename}'
            
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ï¼ˆUTF-8 BOMä»˜ãã§ä¿å­˜ã—ã¦Excelã§ã‚‚æ­£ã—ãè¡¨ç¤ºï¼‰
            df.to_csv(filepath, index=False, encoding='utf-8-sig')
            
            print(f"âœ… CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filepath}")
            print(f"ğŸ“Š ä¿å­˜ãƒ‡ãƒ¼ã‚¿: {len(df)}è¡Œ Ã— {len(df.columns)}åˆ—")
            
            return filepath
            
        except Exception as e:
            print(f"âŒ CSVä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def upload_to_spreadsheet(self, csv_path: str) -> bool:
        """
        CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        
        Args:
            csv_path (str): ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            
        Returns:
            bool: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸæ™‚ã¯Trueã€å¤±æ•—æ™‚ã¯False
        """
        try:
            # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å–å¾—
            credentials_path = env.get_service_account_file()
            
            # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆIDã‚’å–å¾—
            spreadsheet_id = env.get_config_value('SPREADSHEET', 'ssid', '')
            if not spreadsheet_id:
                print("âŒ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆIDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return False
            
            print(f"ğŸ“‹ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆID: {spreadsheet_id}")
            print(f"ğŸ” èªè¨¼ãƒ•ã‚¡ã‚¤ãƒ«: {credentials_path}")
            
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            result = upload_csv_to_sheet(csv_path, credentials_path, spreadsheet_id)
            
            if result:
                print("âœ… ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã¸ã®è»¢è¨˜ãŒå®Œäº†ã—ã¾ã—ãŸ")
                return True
            else:
                print("âŒ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã¸ã®è»¢è¨˜ã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False
                
        except Exception as e:
            print(f"âŒ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆè»¢è¨˜ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def sync_data_to_spreadsheet(self, limit: int = 5000) -> bool:
        """
        bâ†’dash APIã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«åŒæœŸ
        
        Args:
            limit (int): å–å¾—ã™ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã®ä¸Šé™
            
        Returns:
            bool: åŒæœŸæˆåŠŸæ™‚ã¯Trueã€å¤±æ•—æ™‚ã¯False
        """
        try:
            print("ğŸš€ bâ†’dash APIãƒ‡ãƒ¼ã‚¿åŒæœŸé–‹å§‹")
            print("=" * 60)
            
            # 1. APIèªè¨¼æƒ…å ±ã®è¨­å®š
            if not self.setup_api_credentials():
                return False
            
            # 2. ãƒ‡ãƒ¼ã‚¿å–å¾—
            data = self.fetch_data(limit)
            if not data:
                return False
            
            # 3. DataFrameã«å¤‰æ›
            df = self.convert_to_dataframe(data)
            if df is None:
                return False
            
            # 4. CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
            csv_path = self.save_to_csv(df)
            if not csv_path:
                return False
            
            # 5. ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            if not self.upload_to_spreadsheet(csv_path):
                return False
            
            print("=" * 60)
            print("ğŸ‰ bâ†’dash APIãƒ‡ãƒ¼ã‚¿åŒæœŸå®Œäº†")
            print(f"ğŸ“Š å‡¦ç†ãƒ‡ãƒ¼ã‚¿: {len(df)}è¡Œ Ã— {len(df.columns)}åˆ—")
            
            # é…ä¿¡å¹´æœˆã®ç¯„å›²ã‚’è¡¨ç¤º
            date_column = None
            for col in df.columns:
                if 'é…ä¿¡å¹´æœˆ' in col or 'å¹´æœˆ' in col:
                    date_column = col
                    break
            
            if date_column and date_column in df.columns:
                date_values = df[date_column].dropna().unique()
                if len(date_values) > 0:
                    print(f"ğŸ“… é…ä¿¡å¹´æœˆã®ç¯„å›²: {min(date_values)} ï½ {max(date_values)}")
                    print(f"ğŸ“Š é…ä¿¡å¹´æœˆã®ç¨®é¡: {len(date_values)}ç¨®é¡")
            
            return True
            
        except Exception as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿åŒæœŸã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            return False 